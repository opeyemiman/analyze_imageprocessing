{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b46d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import micasense.imageset as imageset\n",
    "import micasense.capture as capture\n",
    "import os, glob\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import subprocess\n",
    "from micasense import plotutils\n",
    "import micasense.imageutils as imageutils\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import skimage.measure\n",
    "from ipywidgets import Tab, VBox, HBox, HTML, Output\n",
    "import folium\n",
    "from IPython.display import IFrame\n",
    "import json\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "def write_labeled_pixels(\n",
    "        capture,\n",
    "        blue, green, red, rededge, nir,\n",
    "        wen, ndssi, ndwi,\n",
    "        json_data,\n",
    "        y_deres, x_deres,                # your processing deresolution\n",
    "        output_csv_path,\n",
    "        img_format=\".png\",\n",
    "        label_res_y=4, \n",
    "        label_res_x=4\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Fast labeled pixel extractor.\n",
    "    Polygons come from labeling resolution (default 4x4).\n",
    "    They are rescaled to your current resolution automatically.\n",
    "    Bounding box scanning is used for speed.\n",
    "    \"\"\"\n",
    "\n",
    "    uuid = capture.uuid\n",
    "    json_filename = uuid + img_format\n",
    "\n",
    "    # ------------------------------\n",
    "    # 1. Find correct image entry\n",
    "    # ------------------------------\n",
    "    image_id = None\n",
    "    for img in json_data[\"images\"]:\n",
    "        if img[\"file_name\"] == json_filename:\n",
    "            image_id = img[\"id\"]\n",
    "            break\n",
    "\n",
    "    if image_id is None:\n",
    "        return\n",
    "\n",
    "    # ------------------------------\n",
    "    # 2. Compute polygon scale factor\n",
    "    # ------------------------------\n",
    "    scale_x = x_deres / label_res_x\n",
    "    scale_y = y_deres / label_res_y\n",
    "\n",
    "    # ------------------------------\n",
    "    # 3. Build scaled polygons\n",
    "    # ------------------------------\n",
    "    polygons = []\n",
    "    for ann in json_data[\"annotations\"]:\n",
    "        if ann[\"image_id\"] != image_id:\n",
    "            continue\n",
    "\n",
    "        pts = ann[\"segmentation\"][0]\n",
    "        scaled_coords = []\n",
    "\n",
    "        for i in range(0, len(pts), 2):\n",
    "            px = pts[i]   * scale_x\n",
    "            py = pts[i+1] * scale_y\n",
    "            scaled_coords.append((px, py))\n",
    "\n",
    "        poly = Polygon(scaled_coords)\n",
    "        minx, miny, maxx, maxy = poly.bounds\n",
    "\n",
    "        polygons.append({\n",
    "            \"polygon\": poly,\n",
    "            \"category_id\": ann[\"category_id\"],\n",
    "            \"bbox\": (int(minx), int(miny), int(maxx), int(maxy))\n",
    "        })\n",
    "\n",
    "    if len(polygons) == 0:\n",
    "        return\n",
    "\n",
    "    H, W = blue.shape\n",
    "\n",
    "    # ------------------------------\n",
    "    # 4. Open CSV\n",
    "    # ------------------------------\n",
    "    new_file = not os.path.exists(output_csv_path)\n",
    "    f = open(output_csv_path, \"a\", newline=\"\")\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    if new_file:\n",
    "        writer.writerow([\n",
    "            \"uuid\",\"pixely\",\"pixelx\",\n",
    "            \"blue\",\"green\",\"red\",\"rededge\",\"nir\",\n",
    "            \"wen\",\"ndssi\",\"ndwi\",\n",
    "            \"class\"\n",
    "        ])\n",
    "\n",
    "    # ------------------------------\n",
    "    # 5. Bounding box pixel scanning\n",
    "    # ------------------------------\n",
    "    for p in polygons:\n",
    "\n",
    "        poly   = p[\"polygon\"]\n",
    "        cat_id = p[\"category_id\"]\n",
    "        xmin, ymin, xmax, ymax = p[\"bbox\"]\n",
    "\n",
    "        # Clamp bounding box to image boundaries\n",
    "        xmin = max(0, xmin)\n",
    "        ymin = max(0, ymin)\n",
    "        xmax = min(W-1, xmax)\n",
    "        ymax = min(H-1, ymax)\n",
    "\n",
    "        # Scan only inside bounding box\n",
    "        for y in range(ymin, ymax + 1):\n",
    "            for x in range(xmin, xmax + 1):\n",
    "\n",
    "                pt = Point(x, y)\n",
    "                if not (poly.contains(pt) or poly.touches(pt)):\n",
    "                    continue\n",
    "\n",
    "                # Pixel is inside polygon â†’ write it\n",
    "                writer.writerow([\n",
    "                    uuid, y, x,\n",
    "                    blue[y, x], green[y, x], red[y, x], rededge[y, x], nir[y, x],\n",
    "                    wen[y, x], ndssi[y, x], ndwi[y, x],\n",
    "                    cat_id\n",
    "                ])\n",
    "\n",
    "    f.close()\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "def extract_pixels_by_polygon_with_deresolution(csv_file_path, json_file_path, output_csv_path, downscale_factor=(1, 1), im_type='.jpg'):\n",
    "    \"\"\"\n",
    "    Extract pixels from a downsampled CSV file that are bound by polygons from a JSON file generated by makesense.ai labeling tool.\n",
    "    Adjusts for the resolution difference by scaling the pixel coordinates to match the original resolution.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): Path to the downsampled pixels.csv file containing pixel data.\n",
    "        json_file_path (str): Path to the JSON file containing polygon labels and uuids.\n",
    "        output_csv_path (str): Path to the output CSV file that will contain the filtered pixels.\n",
    "        downscale_factor (tuple): The factor by which the resolution was reduced (e.g., (3, 3) for 3x3 blocks).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the downsampled CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()  # Strip whitespace from column names\n",
    "    \n",
    "    # Ensure the dataframe contains the required columns\n",
    "    if 'uuid' not in df.columns or 'pixely' not in df.columns or 'pixelx' not in df.columns:\n",
    "        raise ValueError(\"The CSV must contain 'uuid', 'pixely', and 'pixelx' columns.\")\n",
    "    \n",
    "    # Load the JSON file (labels from makesense.ai)\n",
    "    with open(json_file_path) as f:\n",
    "        label_data = json.load(f)\n",
    "    \n",
    "    # Extract the annotations and images from the JSON\n",
    "    annotations = label_data['annotations']\n",
    "    images_info = label_data['images']\n",
    "    \n",
    "    # Create a mapping of image ids to uuids (strip '.jpg' from filenames)\n",
    "    image_id_to_uuid = {image['id']: image['file_name'].replace(im_type, '') for image in images_info}\n",
    "    \n",
    "    # Initialize an empty list to store filtered pixel data\n",
    "    filtered_pixels = []\n",
    "    \n",
    "    # Scale factor for pixel coordinates to map back to original resolution\n",
    "    scale_y, scale_x = downscale_factor\n",
    "    \n",
    "    # Iterate through each annotation (polygon)\n",
    "    for annotation in annotations:\n",
    "        image_id = annotation['image_id']\n",
    "        image_uuid = image_id_to_uuid[image_id]  # Get the image UUID (filename)\n",
    "        \n",
    "        # Get the segmentation points (polygon) in the original resolution\n",
    "        polygon_points = annotation['segmentation'][0]\n",
    "        polygon_coords = [(polygon_points[i], polygon_points[i + 1]) for i in range(0, len(polygon_points), 2)]\n",
    "        \n",
    "        # Create a Polygon object using shapely\n",
    "        polygon = Polygon(polygon_coords)\n",
    "        \n",
    "        # Filter the pixels from the CSV that correspond to this image's UUID\n",
    "        image_pixels = df[df['uuid'] == image_uuid]\n",
    "        \n",
    "        # Check which pixels are inside the polygon in the original resolution\n",
    "        for _, pixel_row in image_pixels.iterrows():\n",
    "            # Scale up the coordinates to the original resolution\n",
    "            original_x = pixel_row['pixelx'] * scale_x\n",
    "            original_y = pixel_row['pixely'] * scale_y\n",
    "            \n",
    "            # Since the downsampled pixel represents a block, we check the block\n",
    "            block_corners = [\n",
    "                (original_x, original_y), \n",
    "                (original_x + scale_x - 1, original_y), \n",
    "                (original_x, original_y + scale_y - 1), \n",
    "                (original_x + scale_x - 1, original_y + scale_y - 1)\n",
    "            ]\n",
    "            \n",
    "            # If any of the block corners fall inside the polygon, keep the pixel\n",
    "            if any(polygon.contains(Point(corner)) for corner in block_corners):\n",
    "                filtered_pixels.append(pixel_row)\n",
    "    \n",
    "    # Create a new DataFrame from the filtered pixels and save to CSV\n",
    "    filtered_df = pd.DataFrame(filtered_pixels)\n",
    "    filtered_df.to_csv(output_csv_path, index=False)\n",
    "    \n",
    "    print(f\"Filtered pixels saved to {output_csv_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "def im_reduction3d(im_aligned,y_div=1, x_div=1):\n",
    "    #dimension of im_aligned is typically array is 1280 x 960\n",
    "\n",
    "    new_array=skimage.measure.block_reduce(im_aligned,(y_div, x_div,1),np.mean)\n",
    "    return new_array\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "def im_reduction2d(im_aligned,y_div=1, x_div=1):\n",
    "    #dimension of im_aligned is typically array is 1280 x 960\n",
    "\n",
    "    new_array=skimage.measure.block_reduce(im_aligned,(y_div, x_div),np.mean)\n",
    "    return new_array\n",
    "\n",
    "####################################################################################################################\n",
    "def acquire_bands(im_aligned,capture,imagePath,plot_outputs=0,save_plots=0):\n",
    "    NIR_path= imagePath /'..'/ 'NIR'\n",
    "    RED_path= imagePath /'..'/ 'RED'\n",
    "    GREEN_path= imagePath /'..'/ 'GREEN'\n",
    "    BLUE_path= imagePath /'..'/ 'BLUE'\n",
    "    REDEDGE_path= imagePath /'..'/ 'REDEDGE'\n",
    "    GREY= imagePath /'..'/ 'GREY'\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    \n",
    "    blue_band = capture.band_names_lower().index('blue')\n",
    "    green_band = capture.band_names_lower().index('green')\n",
    "    red_band = capture.band_names_lower().index('red')\n",
    "    nir_band = capture.band_names_lower().index('nir')\n",
    "    redEdge_band = capture.band_names_lower().index('red edge')\n",
    "    \n",
    "    nir = im_aligned[:,:,capture.band_names_lower().index('nir')]\n",
    "    red =im_aligned[:,:,capture.band_names_lower().index('red')]\n",
    "    green=im_aligned[:,:,capture.band_names_lower().index('green')]\n",
    "    blue=im_aligned[:,:,capture.band_names_lower().index('blue')]\n",
    "    rededge=im_aligned[:,:,capture.band_names_lower().index('red edge')]\n",
    "    \n",
    "    \n",
    "    le_file= capture.uuid +'.png'\n",
    "    \n",
    "    if not os.path.exists(GREY):\n",
    "        os.makedirs(GREY)\n",
    "        \n",
    "    output_GREY = os.path.join(GREY, le_file)\n",
    "    plt.imsave(output_GREY,green,cmap='gray')\n",
    "\n",
    "    if plot_outputs==1:\n",
    "        fig1, axis1 = plotutils.plotwithcolorbar(nir, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'NIR-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = 0,\n",
    "                                                vmax = 1)\n",
    "        fig2, axis2 = plotutils.plotwithcolorbar(green, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'GREEN-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = 0,\n",
    "                                                vmax = 1)\n",
    "        fig3, axis3 = plotutils.plotwithcolorbar(red, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'RED-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = 0,\n",
    "                                                vmax = 1)\n",
    "        fig4, axis4 = plotutils.plotwithcolorbar(rededge, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'REDEDGE-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = 0,\n",
    "                                                vmax = 1)\n",
    "        fig5, axis5 = plotutils.plotwithcolorbar(blue, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'BLUE-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = 0,\n",
    "                                                vmax = 1)\n",
    "    \n",
    "    \n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(NIR_path):\n",
    "            os.makedirs(NIR_path)\n",
    "        output_NIR = os.path.join(NIR_path, le_file)\n",
    "        fig1.savefig(output_NIR) \n",
    "        if not os.path.exists(RED_path):\n",
    "            os.makedirs(RED_path)\n",
    "        output_RED = os.path.join(RED_path, le_file)\n",
    "        fig3.savefig(output_RED) \n",
    "        if not os.path.exists(GREEN_path):\n",
    "            os.makedirs(GREEN_path)\n",
    "        output_GREEN = os.path.join(GREEN_path, le_file)\n",
    "        fig2.savefig(output_GREEN) \n",
    "        if not os.path.exists(BLUE_path):\n",
    "            os.makedirs(BLUE_path)\n",
    "        output_BLUE= os.path.join(BLUE_path, le_file)\n",
    "        fig5.savefig(output_BLUE) \n",
    "        if not os.path.exists(REDEDGE_path):\n",
    "            os.makedirs(REDEDGE_path)\n",
    "        output_REDEDGE = os.path.join(REDEDGE_path, le_file)\n",
    "        fig4.savefig(output_REDEDGE) \n",
    "            \n",
    "    \n",
    "        \n",
    "    \n",
    "    return nir,red,green,blue,rededge\n",
    "############################################################################################################################\n",
    "def NDVI_calculator(red,nir,capture,imagePath,v_min=-1,v_max=1,use_percentiles=0,plot_outputs=0,save_plots=0):\n",
    "    \n",
    "    NDVI_path= imagePath /'..'/ 'NDVI'\n",
    "     \n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    #ignore division by zeros and calculate NDVI    \n",
    "    np.seterr(divide='ignore', invalid='ignore')           \n",
    "    ndvi = (nir - red) / (nir + red)\n",
    "    \n",
    " \n",
    "    if use_percentiles==1: \n",
    "        min_display_ndvi = np.percentile(ndvi.flatten(),v_min) # further mask soil by removing low-ndvi values\n",
    "        max_display_ndvi = np.percentile(ndvi.flatten(), v_max)\n",
    "    else:\n",
    "        min_display_ndvi = v_min \n",
    "        max_display_ndvi = v_max\n",
    "   \n",
    "\n",
    "\n",
    "    #reduce the figure size to account for colorbar\n",
    "    # figsize=(30,23) # use this size for full-image-resolution display\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    NDVI_file= capture.uuid +'.png'\n",
    "    \n",
    "    if plot_outputs:\n",
    "        fig, axis = plotutils.plotwithcolorbar(ndvi, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'NDVI-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = min_display_ndvi,\n",
    "                                                vmax = max_display_ndvi)\n",
    "    \n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(NDVI_path):\n",
    "            os.makedirs(NDVI_path)\n",
    "        output_NDVI = os.path.join(NDVI_path, NDVI_file)\n",
    "        fig.savefig(output_NDVI) \n",
    "    \n",
    "      \n",
    "    return ndvi\n",
    "\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "def greyscale_acquire(im_aligned,capture,imagePath):\n",
    "    \n",
    "    GREY= imagePath /'..'/ 'GREYSCALE'\n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    green_band = capture.band_names_lower().index('green')\n",
    "    green=im_aligned[:,:,capture.band_names_lower().index('green')]\n",
    "    \n",
    "    le_file= capture.uuid +'.png'\n",
    "    \n",
    "    if not os.path.exists(GREY):\n",
    "        os.makedirs(GREY)    \n",
    "    output_GREY = os.path.join(GREY, le_file)\n",
    "    plt.imsave(output_GREY,green,cmap='gray')\n",
    "\n",
    "    \n",
    "###################################################################################################################   \n",
    "def NDSSI_calculator(blue,nir,capture,imagePath,v_min=-1,v_max=1,use_percentiles=0,plot_outputs=1,save_plots=0):\n",
    "\n",
    "    \n",
    "    ndssi_path= imagePath /'..'/ 'ndssi'\n",
    "     \n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    #ignore division by zeros and calculate NDVI    \n",
    "    np.seterr(divide='ignore', invalid='ignore')           \n",
    "    ndssi = (blue - nir) / (blue + nir)\n",
    "    \n",
    " \n",
    "    if use_percentiles==1: \n",
    "        min_display_ndssi = np.percentile(ndssi.flatten(),v_min) # further mask soil by removing low-ndvi values\n",
    "        max_display_ndssi = np.percentile(ndssi.flatten(), v_max)\n",
    "    else:\n",
    "        min_display_ndssi = v_min \n",
    "        max_display_ndssi = v_max\n",
    "   \n",
    "\n",
    "\n",
    "    #reduce the figure size to account for colorbar\n",
    "    # figsize=(30,23) # use this size for full-image-resolution display\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    ndssi_file= capture.uuid +'.png'\n",
    "    \n",
    "    if plot_outputs:\n",
    "        fig, axis = plotutils.plotwithcolorbar(ndssi, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'ndssi-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = min_display_ndssi,\n",
    "                                                vmax = max_display_ndssi)\n",
    "    \n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(ndssi_path):\n",
    "            os.makedirs(ndssi_path)\n",
    "        output_ndssi = os.path.join(ndssi_path, ndssi_file)\n",
    "        fig.savefig(output_ndssi) \n",
    "      \n",
    "    return ndssi\n",
    "    \n",
    "##################################################################################################################\n",
    "def wen_algo(red,green,capture,imagePath,v_min=-1,v_max=1,use_percentiles=0,plot_outputs=1,save_plots=0):\n",
    "    #wen\n",
    "    \n",
    "    wen_path= imagePath /'..'/ 'wen_algo'\n",
    "     \n",
    "        \n",
    "    #ignore division by zeros and calculate NDVI    \n",
    "    np.seterr(divide='ignore', invalid='ignore')           \n",
    "    wen = 3793.7 * np.power((green + red), 2) - 16.5\n",
    "\n",
    " \n",
    "    if use_percentiles==1: \n",
    "        min_display_wen = np.percentile(wen.flatten(), v_min) # further mask soil by removing low-ndvi values\n",
    "        max_display_wen = np.percentile(wen.flatten(), v_max)\n",
    "    else:\n",
    "        min_display_wen = v_min \n",
    "        max_display_wen = v_max\n",
    "   \n",
    "\n",
    "\n",
    "    #reduce the figure size to account for colorbar\n",
    "    # figsize=(30,23) # use this size for full-image-resolution display\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    wen_file= capture.uuid +'.png'\n",
    "    \n",
    "    if plot_outputs:\n",
    "        fig, axis = plotutils.plotwithcolorbar(wen, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'wen-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = min_display_wen,\n",
    "                                                vmax = max_display_wen)\n",
    "    \n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(wen_path):\n",
    "            os.makedirs(wen_path)\n",
    "        output_wen = os.path.join(wen_path, wen_file)\n",
    "        fig.savefig(output_wen) \n",
    "      \n",
    "    return wen\n",
    "\n",
    "            \n",
    "#####################################################################################################################\n",
    "def NDWI_calculator(green,nir,capture,imagePath,v_min=-1,v_max=1,use_percentiles=0,plot_outputs=0,save_plots=0):\n",
    "\n",
    "    \n",
    "    NDWI_path= imagePath /'..'/ 'NDWI'\n",
    "     \n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    #ignore division by zeros and calculate NDVI    \n",
    "    np.seterr(divide='ignore', invalid='ignore')           \n",
    "    ndwi = (green - nir) / (green + nir)\n",
    "    \n",
    " \n",
    "    if use_percentiles==1: \n",
    "        min_display_ndwi = np.percentile(ndwi.flatten(),v_min) # further mask soil by removing low-ndvi values\n",
    "        max_display_ndwi = np.percentile(ndwi.flatten(), v_max)\n",
    "    else:\n",
    "        min_display_ndwi = v_min \n",
    "        max_display_ndwi = v_max\n",
    "   \n",
    "\n",
    "\n",
    "    #reduce the figure size to account for colorbar\n",
    "    # figsize=(30,23) # use this size for full-image-resolution display\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    NDWI_file= capture.uuid +'.png'\n",
    "    \n",
    "    if plot_outputs:\n",
    "        fig, axis = plotutils.plotwithcolorbar(ndwi, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'NDWI-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = min_display_ndwi,\n",
    "                                                vmax = max_display_ndwi)\n",
    "    \n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(NDWI_path):\n",
    "            os.makedirs(NDWI_path)\n",
    "        output_NDWI = os.path.join(NDWI_path, NDWI_file)\n",
    "        fig.savefig(output_NDWI) \n",
    "      \n",
    "    return ndwi\n",
    "            \n",
    "\n",
    "###################################################################################################################\n",
    "def cir_composite(im_aligned,capture,imagePath):\n",
    "    cir_band_indices = [capture.band_names_lower().index('nir'),\n",
    "                    capture.band_names_lower().index('red'),\n",
    "                    capture.band_names_lower().index('green')]\n",
    "    \n",
    "    CIR_path= imagePath /'..'/ 'CIR'\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    if not os.path.exists(CIR_path):\n",
    "        os.makedirs(CIR_path)\n",
    "  \n",
    "    \n",
    "    im_display = np.zeros((im_aligned.shape[0],im_aligned.shape[1],im_aligned.shape[2]), dtype=np.float32 )\n",
    "    \n",
    "    #figsize=(30,23) # use this size for full-image-resolution display\n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    " \n",
    "    \n",
    "    for i in cir_band_indices:\n",
    "        im_display[:,:,i] =  imageutils.normalize(im_aligned[:,:,i])\n",
    "        \n",
    "    cir = im_display[:,:,cir_band_indices]\n",
    "    \n",
    "\n",
    "    CIR_file= capture.uuid +'.png'\n",
    "    \n",
    "    fig,axis=plotutils.plotwithcolorbar(cir,\n",
    "                                          figsize=figsize,\n",
    "                                          title = f'Color Infrared Composite-{capture.uuid}-{capture.location()}')\n",
    "    \n",
    "    output_CIR = os.path.join(CIR_path, CIR_file)\n",
    "    \n",
    "    fig.savefig(output_CIR)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return cir\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "def custom_signed_band_calculator(band1,band2,band3,band4,capture,imagePath,v_min=-1,v_max=1,use_percentiles=0,plot_outputs=0,save_plots=0):\n",
    "\n",
    "    \n",
    "    custom_path= imagePath /'..'/ 'Custom'\n",
    "     \n",
    "    if not os.path.exists(custom_path):\n",
    "        os.makedirs(custom_path)\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    #ignore division by zeros and calculate NDVI    \n",
    "    np.seterr(divide='ignore', invalid='ignore')           \n",
    "    custom = (band1 + band2) / (band3 + band4)\n",
    "    \n",
    " \n",
    "    if use_percentiles==1: \n",
    "        min_display_custom = np.percentile(custom.flatten(),v_min) # further mask soil by removing low-ndvi values\n",
    "        max_display_custom = np.percentile(custom.flatten(), v_max)\n",
    "    else:\n",
    "        min_display_custom = v_min \n",
    "        max_display_custom = v_max\n",
    "   \n",
    "\n",
    "\n",
    "    #reduce the figure size to account for colorbar\n",
    "    # figsize=(30,23) # use this size for full-image-resolution display\n",
    "    \n",
    "    figsize=(16,13)   # use this size for export-sized display\n",
    "    figsize=np.asarray(figsize) - np.array([3,2])\n",
    "    \n",
    "    custom_file= capture.uuid +'.png'\n",
    "    \n",
    "    if plot_outputs:\n",
    "        fig, axis = plotutils.plotwithcolorbar(custom, \n",
    "                                                figsize = figsize, \n",
    "                                                title = f'Custom-{capture.uuid}-{capture.location()}',\n",
    "                                                vmin = min_display_custom,\n",
    "                                                vmax = max_display_custom)\n",
    "    if plot_outputs==1 & save_plots==1:\n",
    "        if not os.path.exists(custom_path):\n",
    "            os.makedirs(custom_path)\n",
    "        output_custom = os.path.join(custom_path, custom_file)\n",
    "        fig.savefig(output_custom) \n",
    "      \n",
    "    return custom\n",
    "            \n",
    "################################################################################################################\n",
    "def capturepixellister(wen,ndssi,ndwi,blue,green,red,rededge,nir,capture,outputPath):\n",
    "    \n",
    "    \n",
    "    if os.path.exists(os.path.join(outputPath,'pixels.csv')):\n",
    "        lines=[]\n",
    "    else:\n",
    "        lines = [\"SourceFile,uuid,\\\n",
    "        GPSDateStamp,GPSTimeStamp,\\\n",
    "        GPSLatitude,GPSLongitude,GPSAltitude,\\\n",
    "        pixely,pixelx,\\\n",
    "        wen,ndssi,ndwi,blue,green,red,rededge,nir,class\\n\"]\n",
    "  \n",
    "  \n",
    "    #lines=[header]\n",
    "    \n",
    "    outputFilename = capture.uuid+'.tif'\n",
    "    fullOutputPath = os.path.join(outputPath, outputFilename)\n",
    "    lat,lon,alt = capture.location()\n",
    "    \n",
    "    if os.path.exists(os.path.join(outputPath,'pixels.csv')):\n",
    "        for i in range(ndwi.shape[0]):  # height\n",
    "            for j in range(ndwi.shape[1]):  # width\n",
    "                wen_pixel = wen[i, j]\n",
    "                ndssi_pixel = ndssi[i, j]\n",
    "                ndwi_pixel = ndwi[i, j]\n",
    "                blue_pixel = blue[i, j]\n",
    "                green_pixel = green[i, j]\n",
    "                red_pixel = red[i, j]\n",
    "                rededge_pixel = rededge[i, j]\n",
    "                nir_pixel = nir[i, j]\n",
    "  \n",
    "\n",
    "                linestr = '\"{}\",{},'.format(fullOutputPath,capture.uuid)\n",
    "                linestr += capture.utc_time().strftime(\"%Y:%m:%d,%H:%M:%S,\")\n",
    "                linestr += '{},{},{},'.format(lat,lon,alt)\n",
    "                linestr += '{},{},'.format(i,j)\n",
    "                linestr += '{},{},{},{},{},{},{},{},{}'.format(wen_pixel,ndssi_pixel,ndwi_pixel,blue_pixel,green_pixel,red_pixel,rededge_pixel,nir_pixel,custom_pixel)\n",
    "                linestr += '\\n' # when writing in text mode, the write command will convert to os.linesep\n",
    "                lines.append(linestr)\n",
    "            \n",
    "    fullCsvPath = os.path.join(outputPath,'pixels.csv')\n",
    "    with open(fullCsvPath, 'a') as csvfile: #create CSV\n",
    "        csvfile.writelines(lines)\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "\n",
    "def analyze_pixel_data_from_csv(csv_file_path, band_ranges, height_sections):\n",
    "    \"\"\"\n",
    "    Analyzes pixel data for multiple captures by parsing the entire CSV file, grouping data by the 'uuid' column,\n",
    "    and generating plots and statistics for each band and section. The results are displayed in tabs.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): Path to the CSV file containing pixel data. There must be a 'uuid' column for each capture.\n",
    "        band_ranges (dict): A dictionary where keys are band names (e.g., 'red', 'green') \n",
    "                            and values are tuples with major and minor ranges like: \n",
    "                            {'red': ((0.2, 1.0), (0.5, 0.7)), 'green': ((0.1, 0.9), (0.3, 0.6))}\n",
    "        height_sections (int): Number of vertical sections to divide the image into.\n",
    "        \n",
    "    Returns:\n",
    "        Displays a tab-based interface to traverse the results per capture (by 'uuid').\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the CSV and strip any leading/trailing spaces from column names\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()  # Strip whitespace from column names\n",
    "\n",
    "    # Ensure the 'uuid' column exists\n",
    "    if 'uuid' not in df.columns:\n",
    "        raise ValueError(\"The CSV file must contain a 'uuid' column with capture names.\")\n",
    "    \n",
    "    # Handle different possible column names for 'pixely'\n",
    "    possible_pixely_columns = ['pixely', 'y', 'pixel_y', 'y_coord']\n",
    "    pixely_col = next((col for col in possible_pixely_columns if col in df.columns), None)\n",
    "    \n",
    "    if pixely_col is None:\n",
    "        raise ValueError(\"Could not find a suitable column for pixel y-coordinates ('pixely', 'y', 'pixel_y', etc.).\")\n",
    "\n",
    "    # Get unique capture uuids from the 'uuid' column\n",
    "    capture_uuids = df['uuid'].unique()\n",
    "\n",
    "    # Dictionary to store analysis results per capture\n",
    "    results_per_capture = {}\n",
    "\n",
    "    # Loop through each unique capture uuid\n",
    "    for capture_uuid in capture_uuids:\n",
    "        capture_df = df[df['uuid'] == capture_uuid].copy()  # Use `.copy()` to avoid setting with copy warning\n",
    "        \n",
    "        # Get image height using the correct y-coordinate column\n",
    "        max_height = capture_df[pixely_col].max() + 1  # Use the identified column for y-coordinates\n",
    "        section_height = max_height // height_sections\n",
    "        capture_df.loc[:, 'height_section'] = capture_df[pixely_col] // section_height  # Fixing the SettingWithCopyWarning\n",
    "\n",
    "        # Dictionary to store minor range percentages and HTML outputs for the capture\n",
    "        capture_data = {\n",
    "            'minor_range_percentages': {},\n",
    "            'plots': []\n",
    "        }\n",
    "\n",
    "        # Loop through each band and its associated ranges\n",
    "        for band, (major_range, minor_range) in band_ranges.items():\n",
    "            # Check if the band_column exists\n",
    "            if band not in capture_df.columns:\n",
    "                raise ValueError(f\"Band column '{band}' not found in the data.\")\n",
    "            \n",
    "            # Store statistics and plots for each section\n",
    "            for section in range(height_sections):\n",
    "                section_pixel_values = capture_df[capture_df['height_section'] == section][band]\n",
    "\n",
    "                # Count pixels in the major and minor range for this section\n",
    "                major_pixels = section_pixel_values[(section_pixel_values >= major_range[0]) & (section_pixel_values <= major_range[1])]\n",
    "                minor_pixels = section_pixel_values[(section_pixel_values >= minor_range[0]) & (section_pixel_values <= minor_range[1])]\n",
    "                \n",
    "                total_pixels_in_section = len(section_pixel_values)\n",
    "                total_pixels_in_major = len(major_pixels)\n",
    "                total_pixels_in_minor = len(minor_pixels)\n",
    "                \n",
    "                # Calculate the percentage of pixels in the minor range\n",
    "                section_minor_percentage = (total_pixels_in_minor / total_pixels_in_major) * 100 if total_pixels_in_major > 0 else 0\n",
    "\n",
    "                # Create the plot for this section\n",
    "                fig, ax = plt.subplots(figsize=(10, 6))\n",
    "                ax.hist(section_pixel_values, bins=50, color='blue', edgecolor='black', alpha=0.7)\n",
    "                ax.axvspan(minor_range[0], minor_range[1], color='red', alpha=0.3, label='Minor Range')\n",
    "                ax.axvspan(major_range[0], major_range[1], color='green', alpha=0.3, label='Major Range')\n",
    "                ax.set_title(f'{band.capitalize()} Pixel Value Distribution in Section {section+1} - {capture_uuid}')\n",
    "                ax.set_xlabel(f'{band.capitalize()} Value')\n",
    "                ax.set_ylabel('Number of Pixels')\n",
    "                ax.legend()\n",
    "\n",
    "                # Create an Output widget to capture the plot\n",
    "                plot_output = Output()\n",
    "                with plot_output:\n",
    "                    plt.show(fig)\n",
    "                plt.close(fig)  # Close the figure to avoid memory issues\n",
    "\n",
    "                # HTML output for the stats displayed beside the plot\n",
    "                stats_html = f\"\"\"\n",
    "                <h4>Section {section+1} Stats</h4>\n",
    "                <p>Total Pixels in Major Range: {total_pixels_in_major}</p>\n",
    "                <p>Total Pixels in Minor Range: {total_pixels_in_minor}</p>\n",
    "                <p>Minor Range Percentage: {section_minor_percentage:.2f}%</p>\n",
    "                \"\"\"\n",
    "\n",
    "                # Create an HBox layout to put the plot and stats side by side\n",
    "                plot_html = HBox([plot_output, HTML(stats_html)])\n",
    "                capture_data['plots'].append(plot_html)\n",
    "\n",
    "        # Save the data for this capture\n",
    "        results_per_capture[capture_uuid] = capture_data\n",
    "    \n",
    "    # Create tabs to display each capture's data\n",
    "    tab_children = []\n",
    "    tab_titles = []\n",
    "\n",
    "    for capture_uuid, data in results_per_capture.items():\n",
    "        # Create a vertical layout to display the plots and stats for all sections\n",
    "        tab_contents = VBox(data['plots'])\n",
    "        tab_children.append(tab_contents)\n",
    "        tab_titles.append(capture_uuid)\n",
    "\n",
    "    # Create a tab widget\n",
    "    tabs = Tab(children=tab_children)\n",
    "    for idx, title in enumerate(tab_titles):\n",
    "        tabs.set_title(idx, title)\n",
    "\n",
    "    # Display the tabs in the notebook\n",
    "    display(tabs)\n",
    "\n",
    "# Example usage:\n",
    "# band_ranges = {'red': ((0.2, 1.0), (0.5, 0.7)), 'green': ((0.1, 0.9), (0.3, 0.6))}\n",
    "# analyze_pixel_data_from_csv('path_to_pixels.csv', band_ranges, 5)\n",
    "\n",
    "    \n",
    "\n",
    "####################################################################################################################\n",
    "def masker(imagePath,csv_file_path, band_mask_ranges, image_shape, plot_outputs=0, save_plots=0, plot_overlay=0, save_overlay=0):\n",
    "    \"\"\"\n",
    "    Masks pixels based on values in multiple bands from a CSV file (pixels.csv) for each unique capture (uuid).\n",
    "    Uses 'pixelx' and 'pixely' to determine pixel positions for the mask. Optionally generates plots for the mask\n",
    "    and an overlay of the mask on the original image.\n",
    "\n",
    "    Parameters:\n",
    "        csv_file_path (str): Path to the pixels.csv file containing pixel data.\n",
    "        band_mask_ranges (dict): A dictionary where each key is a band (e.g., 'ndvi', 'ndwi') and the value is a tuple (m_min, m_max).\n",
    "        image_shape (tuple): Shape of the image as (height, width) to reconstruct the mask correctly.\n",
    "        plot_outputs (bool): If True, plots the mask.\n",
    "        save_plots (bool): If True, saves the mask plot.\n",
    "        plot_overlay (bool): If True, generates an overlay plot with the mask.\n",
    "        save_overlay (bool): If True, saves the overlay plot.\n",
    "        fullThumbnailPath (str): Path to the original thumbnail image for overlay.\n",
    "\n",
    "    Returns:\n",
    "        None (Masks and plots are generated for each unique capture in the CSV for each band).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Ensure the dataframe contains the required columns\n",
    "    required_columns = ['uuid', 'pixely', 'pixelx']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"The required column '{col}' was not found in the CSV.\")\n",
    "    \n",
    "    # Ensure all band columns are in the dataframe\n",
    "    for band in band_mask_ranges.keys():\n",
    "        if band not in df.columns:\n",
    "            raise ValueError(f\"The band '{band}' was not found in the CSV.\")\n",
    "    \n",
    "    # Get the height and width of the image\n",
    "    height, width = image_shape\n",
    "    \n",
    "    \n",
    "    # Iterate through each unique capture (uuid)\n",
    "    for capture_uuid in df['uuid'].unique():\n",
    "        # Filter data for this specific capture\n",
    "        capture_df = df[df['uuid'] == capture_uuid]\n",
    "\n",
    "        # Ensure the capture has data\n",
    "        if capture_df.empty:\n",
    "            print(f\"No data found for capture UUID '{capture_uuid}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Iterate through each band and its corresponding mask range\n",
    "        for band, (m_min, m_max) in band_mask_ranges.items():\n",
    "            print(f\"Processing band '{band}' for capture '{capture_uuid}' with range [{m_min}, {m_max}]\")\n",
    "\n",
    "            # Create an empty mask array for the entire image\n",
    "            mask_array = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "            # Fill the mask array with values from the band based on pixelx, pixely positions\n",
    "            for _, row in capture_df.iterrows():\n",
    "                x = int(row['pixelx'])  # X coordinate\n",
    "                y = int(row['pixely'])  # Y coordinate\n",
    "                mask_array[y, x] = row[band]  # Set value in mask array\n",
    "\n",
    "            # Apply the mask based on the specified range [m_min, m_max]\n",
    "            masked = np.ma.masked_outside(mask_array, m_min, m_max)\n",
    "\n",
    "            # Plot the mask if needed\n",
    "            if plot_outputs == 1:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(masked, cmap='coolwarm')\n",
    "                plt.title(f'Masked {band} - {capture_uuid}')\n",
    "                plt.colorbar()\n",
    "                if save_plots == 1:\n",
    "                    mask_path = imagePath /'..'/'MASK'\n",
    "                    mask_path.mkdir(exist_ok=True)\n",
    "                    plt.savefig(mask_path / f'{capture_uuid}_{band}_mask.png')\n",
    "                plt.show()\n",
    "\n",
    "            # Generate overlay if requested\n",
    "            if plot_overlay == 1:\n",
    "                GREY= imagePath /'..'/ 'GREY'\n",
    "                GREY_file = capture_uuid+'.png'\n",
    "                output_GREY = os.path.join(GREY, GREY_file)\n",
    "                original_image = plt.imread(output_GREY)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.imshow(original_image, alpha=0.7)\n",
    "                plt.imshow(masked, cmap='coolwarm', alpha=0.3)\n",
    "                plt.title(f'Overlayed Mask on {capture_uuid} ({band})')\n",
    "                plt.colorbar()\n",
    "                if save_overlay == 1:\n",
    "                    overlay_path = imagePath /'..'/ 'OVERLAY'\n",
    "                    overlay_path.mkdir(exist_ok=True)\n",
    "                    plt.savefig(overlay_path / f'{capture_uuid}_{band}_overlay.png')\n",
    "                plt.show()\n",
    "\n",
    "    print(\"Masking completed for all captures and bands.\")\n",
    "############################################################################################################\n",
    "def plot_metadata_csv(file_path,outputPath,save_map=0):\n",
    "    # Read metadata csv\n",
    "    metadata = pd.read_csv(file_path)\n",
    "    \n",
    "    \n",
    "    # Calculate the mean of non-zero GPSLatitude and GPSLongitude values\n",
    "    valid_latitudes = metadata['GPSLatitude'].dropna()\n",
    "    valid_longitudes = metadata['GPSLongitude'].dropna()\n",
    "\n",
    "    lat_mean = valid_latitudes[valid_latitudes != 0.0].mean()\n",
    "    lon_mean = valid_longitudes[valid_longitudes != 0.0].mean()\n",
    "    # Create a map with a basemap style (OpenStreetMap in this case)\n",
    "    m = folium.Map(location=[lat_mean, lon_mean], zoom_start=10, tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}', attr=\"ESRI\")\n",
    "\n",
    "    # Add points to the map\n",
    "    for index, row in metadata.iterrows():\n",
    "        if float(row['GPSLatitude']) == 0.0 and float(row['GPSLongitude']) == 0.0:\n",
    "            folium.Marker([lat_mean, lon_mean], \n",
    "                          popup=f\"SourceFile: {row['SourceFile']}\\n\"\n",
    "                                 f\"Date: {row['GPSDateStamp']}, Time: {row['GPSTimeStamp']}\\n\"\n",
    "                                 f\"Altitude: {row['GPSAltitude']}\").add_to(m)\n",
    "        else:\n",
    "            folium.Marker([float(row['GPSLatitude']), float(row['GPSLongitude'])], \n",
    "                          popup=f\"SourceFile: {row['SourceFile']}\\n\"\n",
    "                                 f\"Date: {row['GPSDateStamp']}, Time: {row['GPSTimeStamp']}\\n\"\n",
    "                                 f\"Altitude: {row['GPSAltitude']}\").add_to(m)\n",
    "\n",
    "    # Display the map in the notebook (using IFrame)\n",
    "    \n",
    "    #IFrame(src=m._to_html(), width=800, height=600)\n",
    "    display(m)\n",
    "    \n",
    "    if save_map:\n",
    "        m.save(outputPath/'metadata_map.html')\n",
    "        \n",
    "###############################################################################################################\n",
    "####################################################################################################################        \n",
    "\n",
    "def dnnmasker(imagePath, csv_file_path, model_path, plot_outputs=0, save_plots=0):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained machine learning model to predict pixel values (1/0 or others) based on band values.\n",
    "    Uses 'pixelx' and 'pixely' to determine pixel positions and outputs the predictions.\n",
    "\n",
    "    Parameters:\n",
    "        imagePath (str or Path): Path to the directory where the images and predictions will be saved.\n",
    "        csv_file_path (str): Path to the pixels.csv file containing pixel data, including GPS data.\n",
    "        model_path (str): Path to the pre-trained model file (pickle format).\n",
    "        plot_outputs (bool): If True, plots the prediction map.\n",
    "        save_plots (bool): If True, saves the prediction plot.\n",
    "\n",
    "    Returns:\n",
    "        None (Predictions, plots, and logs are generated for each unique capture).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure the dataframe contains the required columns\n",
    "    required_columns = ['uuid', 'pixely', 'pixelx', 'blue', 'green', 'red', 'rededge', 'nir', 'GPSLatitude', 'GPSLongitude']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"The required column '{col}' was not found in the CSV.\")\n",
    "    \n",
    "    # Load the pre-trained machine learning model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "    # Determine image dimensions based on the maximum pixelx and pixely values\n",
    "    height = df['pixely'].max() + 1  # +1 to account for zero-based indexing\n",
    "    width = df['pixelx'].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare input data (features) for prediction for the whole dataset\n",
    "    features = df[['ndvi','ndwi','blue', 'green', 'red', 'rededge', 'nir']].values\n",
    "    \n",
    "  \n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    predictions = (model.predict(features)>0.5).astype('int32')\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    df['predictions'] = predictions\n",
    "\n",
    "    # Create a list to store log data for the rflog CSV\n",
    "    log_data = []\n",
    "\n",
    "    # Iterate through each unique capture (uuid)\n",
    "    for capture_uuid in df['uuid'].unique():\n",
    "        # Filter data for this specific capture\n",
    "        capture_df = df[df['uuid'] == capture_uuid]\n",
    "\n",
    "        # Ensure the capture has data\n",
    "        if capture_df.empty:\n",
    "            print(f\"No data found for capture UUID '{capture_uuid}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract GPS coordinates\n",
    "        GPSLatitude = capture_df['GPSLatitude'].iloc[0]\n",
    "        GPSLongitude = capture_df['GPSLongitude'].iloc[0]\n",
    "\n",
    "        # Create an empty array to store predictions for the entire image\n",
    "        prediction_array = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "        # Fill the prediction array with values based on pixelx, pixely positions\n",
    "        for idx, row in capture_df.iterrows():\n",
    "            x = int(row['pixelx'])  # X coordinate\n",
    "            y = int(row['pixely'])  # Y coordinate\n",
    "\n",
    "            # Ensure the pixel coordinates are within the calculated image bounds\n",
    "            if 0 <= x < width and 0 <= y < height:\n",
    "                prediction_array[y, x] = row['predictions']\n",
    "            else:\n",
    "                print(f\"Warning: Pixel coordinates ({x}, {y}) are out of bounds for capture {capture_uuid}.\")\n",
    "\n",
    "        # Calculate the average prediction value for the capture\n",
    "        avg_prediction = capture_df['predictions'].mean()\n",
    "\n",
    "        # Plot the prediction map if needed\n",
    "        if plot_outputs == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(prediction_array, cmap='coolwarm')\n",
    "            plt.title(f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}')\n",
    "            plt.colorbar()\n",
    "\n",
    "            # Save the plot if required\n",
    "            if save_plots == 1:\n",
    "                prediction_path = imagePath / '..' / 'PREDICTIONS'\n",
    "                prediction_path.mkdir(exist_ok=True, parents=True)\n",
    "                filename = f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}.png'\n",
    "                plt.savefig(prediction_path / filename)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        # Append log data (capture name, GPS, and average prediction) for rflog\n",
    "        log_data.append({\n",
    "            'capture_uuid': capture_uuid,\n",
    "            'GPSLatitude': GPSLatitude,\n",
    "            'GPSLongitude': GPSLongitude,\n",
    "            'avg_prediction': avg_prediction\n",
    "        })\n",
    "\n",
    "    # Save the log data as 'rflog.csv' in the same directory as the input CSV\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_csv_path = Path(csv_file_path).parent / 'ML_log.csv'\n",
    "    log_df.to_csv(log_csv_path, index=False)\n",
    "\n",
    "    print(f\"Predictions completed for all captures. Log saved as {log_csv_path}.\")\n",
    "    \n",
    "####################################################################################################################        \n",
    "\n",
    "def probdnnmasker(imagePath, csv_file_path, model_path, plot_outputs=0, save_plots=0):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained machine learning model to predict pixel values (1/0 or others) based on band values.\n",
    "    Uses 'pixelx' and 'pixely' to determine pixel positions and outputs the predictions.\n",
    "\n",
    "    Parameters:\n",
    "        imagePath (str or Path): Path to the directory where the images and predictions will be saved.\n",
    "        csv_file_path (str): Path to the pixels.csv file containing pixel data, including GPS data.\n",
    "        model_path (str): Path to the pre-trained model file (pickle format).\n",
    "        plot_outputs (bool): If True, plots the prediction map.\n",
    "        save_plots (bool): If True, saves the prediction plot.\n",
    "\n",
    "    Returns:\n",
    "        None (Predictions, plots, and logs are generated for each unique capture).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure the dataframe contains the required columns\n",
    "    required_columns = ['uuid', 'pixely', 'pixelx', 'blue', 'green', 'red', 'rededge', 'nir', 'GPSLatitude', 'GPSLongitude']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"The required column '{col}' was not found in the CSV.\")\n",
    "    \n",
    "    # Load the pre-trained machine learning model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "    # Determine image dimensions based on the maximum pixelx and pixely values\n",
    "    height = df['pixely'].max() + 1  # +1 to account for zero-based indexing\n",
    "    width = df['pixelx'].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare input data (features) for prediction for the whole dataset\n",
    "    features = df[['ndvi','ndwi','blue', 'green', 'red', 'rededge', 'nir']].values\n",
    "    \n",
    "  \n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    predictions = model.predict(features)\n",
    "  \n",
    "\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    df['predictions'] = predictions\n",
    "\n",
    "    # Create a list to store log data for the rflog CSV\n",
    "    log_data = []\n",
    "\n",
    "    # Iterate through each unique capture (uuid)\n",
    "    for capture_uuid in df['uuid'].unique():\n",
    "        # Filter data for this specific capture\n",
    "        capture_df = df[df['uuid'] == capture_uuid]\n",
    "\n",
    "        # Ensure the capture has data\n",
    "        if capture_df.empty:\n",
    "            print(f\"No data found for capture UUID '{capture_uuid}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract GPS coordinates\n",
    "        GPSLatitude = capture_df['GPSLatitude'].iloc[0]\n",
    "        GPSLongitude = capture_df['GPSLongitude'].iloc[0]\n",
    "\n",
    "        # Create an empty array to store predictions for the entire image\n",
    "        prediction_array = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "        # Fill the prediction array with values based on pixelx, pixely positions\n",
    "        for idx, row in capture_df.iterrows():\n",
    "            x = int(row['pixelx'])  # X coordinate\n",
    "            y = int(row['pixely'])  # Y coordinate\n",
    "\n",
    "            # Ensure the pixel coordinates are within the calculated image bounds\n",
    "            if 0 <= x < width and 0 <= y < height:\n",
    "                prediction_array[y, x] = row['predictions']\n",
    "            else:\n",
    "                print(f\"Warning: Pixel coordinates ({x}, {y}) are out of bounds for capture {capture_uuid}.\")\n",
    "\n",
    "        # Calculate the average prediction value for the capture\n",
    "        avg_prediction = capture_df['predictions'].mean()\n",
    "\n",
    "        # Plot the prediction map if needed\n",
    "        if plot_outputs == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(prediction_array, cmap='coolwarm')\n",
    "            plt.title(f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}')\n",
    "            plt.colorbar()\n",
    "\n",
    "            # Save the plot if required\n",
    "            if save_plots == 1:\n",
    "                prediction_path = imagePath / '..' / 'PROBPREDICTIONS'\n",
    "                prediction_path.mkdir(exist_ok=True, parents=True)\n",
    "                filename = f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}.png'\n",
    "                plt.savefig(prediction_path / filename)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        # Append log data (capture name, GPS, and average prediction) for rflog\n",
    "        log_data.append({\n",
    "            'capture_uuid': capture_uuid,\n",
    "            'GPSLatitude': GPSLatitude,\n",
    "            'GPSLongitude': GPSLongitude,\n",
    "            'avg_prediction': avg_prediction\n",
    "        })\n",
    "\n",
    "    # Save the log data as 'rflog.csv' in the same directory as the input CSV\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_csv_path = Path(csv_file_path).parent / 'ML_prob_log.csv'\n",
    "    log_df.to_csv(log_csv_path, index=False)\n",
    "\n",
    "    print(f\"Predictions completed for all captures. Log saved as {log_csv_path}.\")\n",
    "\n",
    "##############################################################################################################\n",
    "def rfmasker(imagePath, csv_file_path, model_path, plot_outputs=0, save_plots=0):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained machine learning model to predict pixel values (1/0 or others) based on band values.\n",
    "    Uses 'pixelx' and 'pixely' to determine pixel positions and outputs the predictions.\n",
    "\n",
    "    Parameters:\n",
    "        imagePath (str or Path): Path to the directory where the images and predictions will be saved.\n",
    "        csv_file_path (str): Path to the pixels.csv file containing pixel data, including GPS data.\n",
    "        model_path (str): Path to the pre-trained model file (pickle format).\n",
    "        plot_outputs (bool): If True, plots the prediction map.\n",
    "        save_plots (bool): If True, saves the prediction plot.\n",
    "\n",
    "    Returns:\n",
    "        None (Predictions, plots, and logs are generated for each unique capture).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure the dataframe contains the required columns\n",
    "    required_columns = ['uuid', 'pixely', 'pixelx', 'blue', 'green', 'red', 'rededge', 'nir', 'GPSLatitude', 'GPSLongitude']\n",
    "    #for col in required_columns:\n",
    "        #if col not in df.columns:\n",
    "           # raise ValueError(f\"The required column '{col}' was not found in the CSV.\")\n",
    "    \n",
    "    # Load the pre-trained machine learning model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "    # Determine image dimensions based on the maximum pixelx and pixely values\n",
    "    height = df['pixely'].max() + 1  # +1 to account for zero-based indexing\n",
    "    width = df['pixelx'].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare input data (features) for prediction for the whole dataset\n",
    "    features = df[['ndvi','ndwi','blue', 'green', 'red', 'rededge', 'nir']].values\n",
    "    \n",
    "  \n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    predictions = model.predict(features)\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    df['predictions'] = predictions\n",
    "\n",
    "    # Create a list to store log data for the rflog CSV\n",
    "    log_data = []\n",
    "\n",
    "    # Iterate through each unique capture (uuid)\n",
    "    for capture_uuid in df['uuid'].unique():\n",
    "        # Filter data for this specific capture\n",
    "        capture_df = df[df['uuid'] == capture_uuid]\n",
    "\n",
    "        # Ensure the capture has data\n",
    "        if capture_df.empty:\n",
    "            print(f\"No data found for capture UUID '{capture_uuid}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract GPS coordinates\n",
    "        GPSLatitude = capture_df['GPSLatitude'].iloc[0]\n",
    "        GPSLongitude = capture_df['GPSLongitude'].iloc[0]\n",
    "\n",
    "        # Create an empty array to store predictions for the entire image\n",
    "        prediction_array = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "        # Fill the prediction array with values based on pixelx, pixely positions\n",
    "        for idx, row in capture_df.iterrows():\n",
    "            x = int(row['pixelx'])  # X coordinate\n",
    "            y = int(row['pixely'])  # Y coordinate\n",
    "\n",
    "            # Ensure the pixel coordinates are within the calculated image bounds\n",
    "            if 0 <= x < width and 0 <= y < height:\n",
    "                prediction_array[y, x] = row['predictions']\n",
    "            else:\n",
    "                print(f\"Warning: Pixel coordinates ({x}, {y}) are out of bounds for capture {capture_uuid}.\")\n",
    "\n",
    "        # Calculate the average prediction value for the capture\n",
    "        avg_prediction = capture_df['predictions'].mean()\n",
    "\n",
    "        # Plot the prediction map if needed\n",
    "        if plot_outputs == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(prediction_array, cmap='coolwarm')\n",
    "            plt.title(f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}')\n",
    "            plt.colorbar()\n",
    "\n",
    "            # Save the plot if required\n",
    "            if save_plots == 1:\n",
    "                prediction_path = imagePath / '..' / 'PREDICTIONS'\n",
    "                prediction_path.mkdir(exist_ok=True, parents=True)\n",
    "                filename = f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}.png'\n",
    "                plt.savefig(prediction_path / filename)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        # Append log data (capture name, GPS, and average prediction) for rflog\n",
    "        log_data.append({\n",
    "            'capture_uuid': capture_uuid,\n",
    "            'GPSLatitude': GPSLatitude,\n",
    "            'GPSLongitude': GPSLongitude,\n",
    "            'avg_prediction': avg_prediction\n",
    "        })\n",
    "\n",
    "    # Save the log data as 'rflog.csv' in the same directory as the input CSV\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_csv_path = Path(csv_file_path).parent / 'ML_log.csv'\n",
    "    log_df.to_csv(log_csv_path, index=False)\n",
    "\n",
    "    print(f\"Predictions completed for all captures. Log saved as {log_csv_path}.\")\n",
    "    \n",
    "####################################################################################################################        \n",
    "\n",
    "def probrfmasker(imagePath, csv_file_path, model_path, plot_outputs=0, save_plots=0):\n",
    "    \"\"\"\n",
    "    Applies a pre-trained machine learning model to predict pixel values (1/0 or others) based on band values.\n",
    "    Uses 'pixelx' and 'pixely' to determine pixel positions and outputs the predictions.\n",
    "\n",
    "    Parameters:\n",
    "        imagePath (str or Path): Path to the directory where the images and predictions will be saved.\n",
    "        csv_file_path (str): Path to the pixels.csv file containing pixel data, including GPS data.\n",
    "        model_path (str): Path to the pre-trained model file (pickle format).\n",
    "        plot_outputs (bool): If True, plots the prediction map.\n",
    "        save_plots (bool): If True, saves the prediction plot.\n",
    "\n",
    "    Returns:\n",
    "        None (Predictions, plots, and logs are generated for each unique capture).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the pixel data from the CSV file\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    # Ensure the dataframe contains the required columns\n",
    "    required_columns = ['uuid', 'pixely', 'pixelx', 'blue', 'green', 'red', 'rededge', 'nir', 'GPSLatitude', 'GPSLongitude']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"The required column '{col}' was not found in the CSV.\")\n",
    "    \n",
    "    # Load the pre-trained machine learning model\n",
    "    model = pickle.load(open(model_path, \"rb\"))\n",
    "\n",
    "    # Determine image dimensions based on the maximum pixelx and pixely values\n",
    "    height = df['pixely'].max() + 1  # +1 to account for zero-based indexing\n",
    "    width = df['pixelx'].max() + 1\n",
    "\n",
    "\n",
    "\n",
    "    # Prepare input data (features) for prediction for the whole dataset\n",
    "    features = df[['ndvi','ndwi','blue', 'green', 'red', 'rededge', 'nir']].values\n",
    "    \n",
    "  \n",
    "\n",
    "    # Make predictions for the entire dataset\n",
    "    predictions = model.predict_proba(features)\n",
    "  \n",
    "\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    df['predictions'] = predictions[:,1]\n",
    "\n",
    "    # Create a list to store log data for the rflog CSV\n",
    "    log_data = []\n",
    "\n",
    "    # Iterate through each unique capture (uuid)\n",
    "    for capture_uuid in df['uuid'].unique():\n",
    "        # Filter data for this specific capture\n",
    "        capture_df = df[df['uuid'] == capture_uuid]\n",
    "\n",
    "        # Ensure the capture has data\n",
    "        if capture_df.empty:\n",
    "            print(f\"No data found for capture UUID '{capture_uuid}'. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Extract GPS coordinates\n",
    "        GPSLatitude = capture_df['GPSLatitude'].iloc[0]\n",
    "        GPSLongitude = capture_df['GPSLongitude'].iloc[0]\n",
    "\n",
    "        # Create an empty array to store predictions for the entire image\n",
    "        prediction_array = np.zeros((height, width), dtype=np.float32)\n",
    "\n",
    "        # Fill the prediction array with values based on pixelx, pixely positions\n",
    "        for idx, row in capture_df.iterrows():\n",
    "            x = int(row['pixelx'])  # X coordinate\n",
    "            y = int(row['pixely'])  # Y coordinate\n",
    "\n",
    "            # Ensure the pixel coordinates are within the calculated image bounds\n",
    "            if 0 <= x < width and 0 <= y < height:\n",
    "                prediction_array[y, x] = row['predictions']\n",
    "            else:\n",
    "                print(f\"Warning: Pixel coordinates ({x}, {y}) are out of bounds for capture {capture_uuid}.\")\n",
    "\n",
    "        # Calculate the average prediction value for the capture\n",
    "        avg_prediction = capture_df['predictions'].mean()\n",
    "\n",
    "        # Plot the prediction map if needed\n",
    "        if plot_outputs == 1:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.imshow(prediction_array, cmap='coolwarm')\n",
    "            plt.title(f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}')\n",
    "            plt.colorbar()\n",
    "\n",
    "            # Save the plot if required\n",
    "            if save_plots == 1:\n",
    "                prediction_path = imagePath / '..' / 'PROBPREDICTIONS'\n",
    "                prediction_path.mkdir(exist_ok=True, parents=True)\n",
    "                filename = f'{capture_uuid}_lat{GPSLatitude}_lon{GPSLongitude}_avg{avg_prediction:.2f}.png'\n",
    "                plt.savefig(prediction_path / filename)\n",
    "            \n",
    "            plt.show()\n",
    "\n",
    "        # Append log data (capture name, GPS, and average prediction) for rflog\n",
    "        log_data.append({\n",
    "            'capture_uuid': capture_uuid,\n",
    "            'GPSLatitude': GPSLatitude,\n",
    "            'GPSLongitude': GPSLongitude,\n",
    "            'avg_prediction': avg_prediction\n",
    "        })\n",
    "\n",
    "    # Save the log data as 'rflog.csv' in the same directory as the input CSV\n",
    "    log_df = pd.DataFrame(log_data)\n",
    "    log_csv_path = Path(csv_file_path).parent / 'ML_prob_log.csv'\n",
    "    log_df.to_csv(log_csv_path, index=False)\n",
    "\n",
    "    print(f\"Predictions completed for all captures. Log saved as {log_csv_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed00044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:micasense] *",
   "language": "python",
   "name": "conda-env-micasense-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
